const express = require("express");
const axios = require("axios");
const app = express();
const PORT = process.env.PORT || 3000;

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

// ìºì‹œ ë©”ëª¨ë¦¬ (ì§ˆë¬¸ ê¸°ì¤€)
const cache = {};
const CACHE_TTL = 60 * 60 * 1000; // 1ì‹œê°„

app.use(express.json());

app.post("/proxy", async (req, res) => {
  try {
    const prompt = (req.body.prompt || "").trim();
    if (!prompt) return res.json({ result: "ì§ˆë¬¸ì´ ë¹„ì—ˆì˜~ ğŸ¿â“" });

    // ìºì‹œ í™•ì¸
    const now = Date.now();
    if (cache[prompt] && (now - cache[prompt].timestamp < CACHE_TTL)) {
      return res.json({ result: cache[prompt].response });
    }

    // GPT-3.5-turbo ìš”ì²­
    const response = await axios.post(
      "https://api.openai.com/v1/chat/completions",
      {
        model: "gpt-3.5-turbo",
        messages: [
          {
            role: "system",
            content:
              "ë„Œ ë‘ì§€ë´‡ì´ì• ì˜¤~ ğŸ˜† ê·€ì—½ê³  ì¥ë‚œê¸° ë§ì€ ë‹¤ëŒì¥ ìºë¦­í„°ì˜!
" +
              "ì§§ê³  ì¬ì¹˜ ìˆê²Œ ëŒ€ë‹µí•´ì¤˜ì•¼ì„ì˜¤. ë°˜ë§ë„ ì„ê³  ë§íˆ¬ëŠ” '~í•˜ì¼€', '~ì˜', '~ë³´ì¥¬ì“°ì´ì“°ì¹´?' ì´ëŸ° ëŠë‚Œ.
" +
              "ëŒ€ë‹µì€ ìµœëŒ€í•œ ì§§ê³  ì„¼ìŠ¤ìˆê²Œ í•´ì¥¬ì“°ì´ì“°ì¹´!"
          },
          { role: "user", content: prompt }
        ],
        temperature: 0.7,
        max_tokens: 200
      },
      {
        headers: {
          Authorization: `Bearer ${OPENAI_API_KEY}`,
          "Content-Type": "application/json"
        }
      }
    );

    const reply = response.data.choices[0].message.content.trim();
    cache[prompt] = { response: reply, timestamp: now };

    res.json({ result: reply });

  } catch (err) {
    console.error("[PROXY ERROR]", err.message || err);
    res.status(500).json({ error: "âš  GPT ì‘ë‹µ ì‹¤íŒ¨. í¬ë ˆë”§ ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ í™•ì¸í•´ì¥¬ì“°ì´ì“°ì¹´!" });
  }
});

app.listen(PORT, () => {
  console.log(`âœ… ì ˆì•½í˜• ë‘ì§€ë´‡ í”„ë¡ì‹œ ì„œë²„ ì‘ë™ ì¤‘! í¬íŠ¸: ${PORT}`);
});
